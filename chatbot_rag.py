# chatbot_rag.py

import os
import streamlit as st
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain.chains.question_answering import load_qa_chain
from dotenv import load_dotenv

# Load environment variables (your API key)
load_dotenv()

# Get the Google API Key
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    st.error("GOOGLE_API_KEY not found in environment variables. Please set it in a .env file.")
    st.stop()

genai.configure(api_key=GOOGLE_API_KEY)
print("Available models:")
for m in genai.list_models():
    if "generateContent" in m.supported_generation_methods:
        print(f"- {m.name} (supports generateContent)")
    else:
        print(f"- {m.name}")
# ----------------- 1. Chu·∫©n b·ªã d·ªØ li·ªáu (t·ª´ documents.py ho·∫∑c n·ªôi dung tr·ª±c ti·∫øp) -----------------
company_policy_docs = [
    "Ch√≠nh s√°ch ngh·ªâ ph√©p: M·ªói nh√¢n vi√™n ƒë∆∞·ª£c h∆∞·ªüng 15 ng√†y ngh·ªâ ph√©p c√≥ l∆∞∆°ng m·ªói nƒÉm. C√°c ng√†y ngh·ªâ ph√©p kh√¥ng s·ª≠ d·ª•ng s·∫Ω ƒë∆∞·ª£c chuy·ªÉn sang nƒÉm sau t·ªëi ƒëa 5 ng√†y.",
    "Quy tr√¨nh xin ngh·ªâ ph√©p: Nh√¢n vi√™n ph·∫£i n·ªôp ƒë∆°n xin ngh·ªâ ph√©p qua h·ªá th·ªëng n·ªôi b·ªô √≠t nh·∫•t 3 ng√†y l√†m vi·ªác tr∆∞·ªõc ng√†y ngh·ªâ d·ª± ki·∫øn. Ph√™ duy·ªát cu·ªëi c√πng thu·ªôc v·ªÅ qu·∫£n l√Ω tr·ª±c ti·∫øp.",
    "Ch√≠nh s√°ch l√†m th√™m gi·ªù: M·ªçi c√¥ng vi·ªác l√†m th√™m gi·ªù ph·∫£i ƒë∆∞·ª£c qu·∫£n l√Ω tr·ª±c ti·∫øp ph√™ duy·ªát tr∆∞·ªõc. Ti·ªÅn l√†m th√™m gi·ªù ƒë∆∞·ª£c t√≠nh theo h·ªá s·ªë 1.5 l·∫ßn l∆∞∆°ng c∆° b·∫£n cho c√°c ng√†y trong tu·∫ßn v√† 2.0 l·∫ßn cho cu·ªëi tu·∫ßn/ng√†y l·ªÖ.",
    "Quy t·∫Øc l√†m vi·ªác t·ª´ xa: Nh√¢n vi√™n c√≥ th·ªÉ l√†m vi·ªác t·ª´ xa t·ªëi ƒëa 2 ng√†y m·ªói tu·∫ßn, v·ªõi s·ª± ƒë·ªìng √Ω c·ªßa qu·∫£n l√Ω. C·∫ßn ƒë·∫£m b·∫£o k·∫øt n·ªëi internet ·ªïn ƒë·ªãnh v√† m√¥i tr∆∞·ªùng l√†m vi·ªác ph√π h·ª£p.",
    "Ch√≠nh s√°ch b·∫£o m·∫≠t th√¥ng tin: M·ªçi th√¥ng tin kh√°ch h√†ng v√† d·ªØ li·ªáu n·ªôi b·ªô c√¥ng ty l√† t√†i s·∫£n m·∫≠t. Nghi√™m c·∫•m chia s·∫ª ho·∫∑c ti·∫øt l·ªô th√¥ng tin n√†y cho b√™n th·ª© ba d∆∞·ªõi m·ªçi h√¨nh th·ª©c."
]

# ----------------- 2. T·∫°o Embeddings v√† Vector Store -----------------
# S·ª≠ d·ª•ng GoogleGenerativeAIEmbeddings ƒë·ªÉ t·∫°o embeddings
@st.cache_resource
def get_vector_store():
    # Kh·ªüi t·∫°o m√¥ h√¨nh nh√∫ng c·ªßa Google
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    
    # T·∫°o vector store t·ª´ c√°c t√†i li·ªáu v√† embeddings
    # persist_directory: th∆∞ m·ª•c ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu c·ªßa ChromaDB
    vector_store = Chroma.from_texts(company_policy_docs, embeddings, persist_directory="./chroma_db")
    
    # L∆∞u tr·ªØ vector store ƒë·ªÉ kh√¥ng ph·∫£i t·∫°o l·∫°i m·ªói l·∫ßn ch·∫°y
    vector_store.persist()
    return vector_store

# L·∫•y ho·∫∑c t·∫°o vector store
vector_store = get_vector_store()

# ----------------- 3. Thi·∫øt l·∫≠p Gemini API v√† LangChain Chain -----------------
# Kh·ªüi t·∫°o m√¥ h√¨nh Gemini
llm = ChatGoogleGenerativeAI(model="models/gemini-1.5-flash", temperature=0.2) # temperature=0.2 ƒë·ªÉ c√¢u tr·∫£ l·ªùi √≠t s√°ng t·∫°o h∆°n

# T·∫°o prompt template ƒë·ªÉ h∆∞·ªõng d·∫´n Gemini
# {context} s·∫Ω l√† n∆°i ch·ª©a c√°c ƒëo·∫°n t√†i li·ªáu li√™n quan ƒë∆∞·ª£c t√¨m th·∫•y
# {question} l√† c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
prompt_template = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¢n thi·ªán, ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p trong ng·ªØ c·∫£nh sau.
N·∫øu th√¥ng tin kh√¥ng c√≥ trong ng·ªØ c·∫£nh, vui l√≤ng n√≥i r·∫±ng b·∫°n kh√¥ng th·ªÉ t√¨m th·∫•y th√¥ng tin ƒë√≥.
B·∫°n KH√îNG ƒë∆∞·ª£c tr·∫£ l·ªùi b·∫•t k·ª≥ c√¢u h·ªèi n√†o n·∫±m ngo√†i ph·∫°m vi c·ªßa ng·ªØ c·∫£nh n√†y.
Lu√¥n cung c·∫•p c√¢u tr·∫£ l·ªùi r√µ r√†ng v√† ng·∫Øn g·ªçn.

Ng·ªØ c·∫£nh:
{context}

C√¢u h·ªèi:
{question}

Tr·∫£ l·ªùi:
"""

# T·∫°o LangChain PromptTemplate
prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

# T·∫£i chu·ªói QA (Question Answering)
# chain_type="stuff": ƒë∆∞a t·∫•t c·∫£ c√°c t√†i li·ªáu t√¨m ƒë∆∞·ª£c v√†o m·ªôt prompt duy nh·∫•t
# prompt=prompt: s·ª≠ d·ª•ng prompt template ƒë√£ ƒë·ªãnh nghƒ©a
# llm=llm: s·ª≠ d·ª•ng m√¥ h√¨nh Gemini ƒë√£ kh·ªüi t·∫°o
qa_chain = load_qa_chain(llm=llm, chain_type="stuff", prompt=prompt)

# ----------------- 4. X√¢y d·ª±ng h√†m truy v·∫•n RAG -----------------
def get_gemini_response(question):
    # T√¨m ki·∫øm c√°c t√†i li·ªáu li√™n quan nh·∫•t trong vector store
    # k=2: t√¨m 2 ƒëo·∫°n t√†i li·ªáu g·∫ßn nh·∫•t
    docs = vector_store.similarity_search(question, k=2) 
    
    # Ch·∫°y chu·ªói QA v·ªõi c√¢u h·ªèi v√† c√°c t√†i li·ªáu li√™n quan
    response = qa_chain({"input_documents": docs, "question": question})
    return response["output_text"]

# ----------------- 5. T·∫°o giao di·ªán Chatbot v·ªõi Streamlit -----------------
st.set_page_config(page_title="Chatbot Ch√≠nh s√°ch C√¥ng ty", page_icon="ü§ñ")

st.header("ü§ñ Chatbot Ch√≠nh s√°ch C√¥ng ty (Powered by Gemini)")
st.subheader("H·ªèi t√¥i v·ªÅ ch√≠nh s√°ch ngh·ªâ ph√©p, l√†m th√™m gi·ªù, l√†m vi·ªác t·ª´ xa, v√† b·∫£o m·∫≠t th√¥ng tin.")

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat n·∫øu ch∆∞a c√≥
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# X·ª≠ l√Ω input c·ªßa ng∆∞·ªùi d√πng
if prompt := st.chat_input("B·∫°n c√≥ c√¢u h·ªèi g√¨ v·ªÅ ch√≠nh s√°ch?"):
    # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # L·∫•y ph·∫£n h·ªìi t·ª´ Gemini
    with st.chat_message("assistant"):
        with st.spinner("ƒêang t√¨m c√¢u tr·∫£ l·ªùi..."):
            response = get_gemini_response(prompt)
            st.markdown(response)
    
    # Th√™m ph·∫£n h·ªìi c·ªßa Gemini v√†o l·ªãch s·ª≠
    st.session_state.messages.append({"role": "assistant", "content": response})

st.markdown("---")
st.markdown("L∆∞u √Ω: Chatbot n√†y ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n c√°c ch√≠nh s√°ch ƒë√£ ƒë∆∞·ª£c cung c·∫•p. N·∫øu c√¢u h·ªèi n·∫±m ngo√†i ph·∫°m vi, n√≥ s·∫Ω kh√¥ng cung c·∫•p th√¥ng tin.")