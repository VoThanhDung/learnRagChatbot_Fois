# chatbot_rag_faiss_required_upload.py

import os
import streamlit as st
import fitz  # PyMuPDF
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain.chains.question_answering import load_qa_chain
from dotenv import load_dotenv

# ----------------- 0. Load API Key tá»« .env -----------------
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    st.error("GOOGLE_API_KEY khÃ´ng tÃ¬m tháº¥y trong .env. Vui lÃ²ng cáº¥u hÃ¬nh trÆ°á»›c.")
    st.stop()

genai.configure(api_key=GOOGLE_API_KEY)

# ----------------- 1. UI -----------------
st.set_page_config(page_title="Chatbot ChÃ­nh sÃ¡ch CÃ´ng ty", page_icon="ğŸ¤–")
st.header("ğŸ¤– Chatbot ChÃ­nh sÃ¡ch CÃ´ng ty (Powered by Gemini)")
st.subheader("ğŸ“„ Vui lÃ²ng táº£i lÃªn file PDF Ä‘á»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n.")

uploaded_files = st.file_uploader("Táº£i lÃªn cÃ¡c file PDF", type=["pdf"], accept_multiple_files=True)

# ----------------- 2. TrÃ­ch xuáº¥t ná»™i dung tá»« PDF -----------------
def extract_text_from_pdfs(files):
    documents = []
    for file in files:
        pdf_doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in pdf_doc:
            text += page.get_text()
        documents.append(text)
    return documents

# ----------------- 3. Táº¡o Vector Store -----------------
@st.cache_resource
def get_vector_store_from_pdfs(files):
    texts = extract_text_from_pdfs(files)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    return FAISS.from_texts(texts, embeddings)

# Náº¿u khÃ´ng cÃ³ file, dá»«ng chÆ°Æ¡ng trÃ¬nh
if not uploaded_files:
    st.warning("âš ï¸ Vui lÃ²ng upload Ã­t nháº¥t má»™t file PDF Ä‘á»ƒ sá»­ dá»¥ng chatbot.")
    st.stop()

# Táº¡o vector store tá»« file Ä‘Ã£ upload
vector_store = get_vector_store_from_pdfs(uploaded_files)

# ----------------- 4. Khá»Ÿi táº¡o mÃ´ hÃ¬nh Gemini & Chain -----------------
llm = ChatGoogleGenerativeAI(model="models/gemini-1.5-flash", temperature=0.2)

prompt_template = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vÃ  thÃ¢n thiá»‡n. HÃ£y tráº£ lá»i cÃ¡c cÃ¢u há»i dá»±a trÃªn ná»™i dung cá»§a tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p dÆ°á»›i Ä‘Ã¢y. 

Náº¿u thÃ´ng tin cáº§n thiáº¿t khÃ´ng Ä‘Æ°á»£c nÃªu rÃµ trong tÃ i liá»‡u, báº¡n cÃ³ thá»ƒ dÃ¹ng kiáº¿n thá»©c chung hoáº·c suy luáº­n logic tá»« dá»¯ kiá»‡n Ä‘Ã£ cÃ³ trong tÃ i liá»‡u Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i há»£p lÃ½.

HÃ£y Ä‘áº£m báº£o cÃ¢u tráº£ lá»i rÃµ rÃ ng, máº¡ch láº¡c, dá»… hiá»ƒu vÃ  chÃ­nh xÃ¡c nháº¥t cÃ³ thá»ƒ.

Ngá»¯ cáº£nh:
{context}

CÃ¢u há»i:
{question}

Tráº£ lá»i:
"""

prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
qa_chain = load_qa_chain(llm=llm, chain_type="refine", prompt=prompt)

# ----------------- 5. HÃ m tráº£ lá»i cÃ¢u há»i -----------------
def get_gemini_response(question):
    docs = vector_store.similarity_search(question, k=4)
    response = qa_chain({"input_documents": docs, "question": question})
    return response["output_text"]

# ----------------- 6. Giao diá»‡n Chat -----------------
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ğŸ’¬ Báº¡n muá»‘n há»i gÃ¬?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” Äang tÃ¬m cÃ¢u tráº£ lá»i..."):
            response = get_gemini_response(prompt)
            st.markdown(response)

    st.session_state.messages.append({"role": "assistant", "content": response})

# ----------------- 7. ThÃ´ng tin file Ä‘Ã£ upload -----------------
if uploaded_files:
    st.markdown("---")
    st.success(f"ğŸ“š ÄÃ£ upload {len(uploaded_files)} file:")
    for f in uploaded_files:
        st.markdown(f"- {f.name}")

st.markdown("---")
st.caption("ğŸ’¡ Chatbot nÃ y sá»­ dá»¥ng Gemini vÃ  LangChain Ä‘á»ƒ tráº£ lá»i dá»±a trÃªn ná»™i dung file PDF báº¡n Ä‘Ã£ cung cáº¥p.")
